{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1d9a62c",
   "metadata": {},
   "source": [
    "# Gradient Descent Algorithm for Logistic Regression\n",
    "### Gradient descent is an optimization algorithm which is commonly-used to train machine learning models and neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d7cce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing modules\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "733c832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "x = np.array([[34.62365962451697,78.0246928153624],[30.28671076822607,43.89499752400101],[35.84740876993872,72.90219802708364],[60.18259938620976,86.30855209546826],[79.0327360507101,75.3443764369103],[45.08327747668339,56.3163717815305],[61.10666453684766,96.51142588489624],[75.02474556738889,46.55401354116538],[76.09878670226257,87.42056971926803],[84.43281996120035,43.53339331072109],[95.86155507093572,38.22527805795094],[75.01365838958247,30.60326323428011],[82.30705337399482,76.48196330235604],[69.36458875970939,97.71869196188608],[39.53833914367223,76.03681085115882],[53.9710521485623,89.20735013750205],[69.07014406283025,52.74046973016765],[67.94685547711617,46.67857410673128],[70.66150955499435,92.92713789364831],[76.97878372747498,47.57596364975532],[67.37202754570876,42.83843832029179],[89.67677575072079,65.79936592745237],[50.534788289883,48.85581152764205],[34.21206097786789,44.20952859866288],[77.9240914545704,68.9723599933059],[62.27101367004632,69.95445795447587],[80.1901807509566,44.82162893218353],[93.114388797442,38.80067033713209],[61.83020602312595,50.25610789244621],[38.78580379679423,64.99568095539578],[61.379289447425,72.80788731317097],[85.40451939411645,57.05198397627122],[52.10797973193984,63.12762376881715],[52.04540476831827,69.43286012045222],[40.23689373545111,71.16774802184875],[54.63510555424817,52.21388588061123],[33.91550010906887,98.86943574220611],[64.17698887494485,80.90806058670817],[74.78925295941542,41.57341522824434],[34.1836400264419,75.2377203360134],[83.90239366249155,56.30804621605327],[51.54772026906181,46.85629026349976],[94.44336776917852,65.56892160559052],[82.36875375713919,40.61825515970618],[51.04775177128865,45.82270145776001],[62.22267576120188,52.06099194836679],[77.19303492601364,70.45820000180959],[97.77159928000232,86.7278223300282],[62.07306379667647,96.76882412413983],[91.56497449807442,88.69629254546599],[79.94481794066932,74.16311935043758],[99.2725269292572,60.99903099844988],[90.54671411399852,43.39060180650027],[34.52451385320009,60.39634245837173],[50.2864961189907,49.80453881323059],[49.58667721632031,59.80895099453265],[97.64563396007767,68.86157272420604],[32.57720016809309,95.59854761387875],[74.24869136721598,69.82457122657193],[71.79646205863379,78.45356224515052],[75.3956114656803,85.75993667331619],[35.28611281526193,47.02051394723416],[56.25381749711624,39.26147251058019],[30.05882244669796,49.59297386723685],[44.66826172480893,66.45008614558913],[66.56089447242954,41.09209807936973],[40.45755098375164,97.53518548909936],[49.07256321908844,51.88321182073966],[80.27957401466998,92.11606081344084],[66.74671856944039,60.99139402740988],[32.72283304060323,43.30717306430063],[64.0393204150601,78.03168802018232],[72.34649422579923,96.22759296761404],[60.45788573918959,73.09499809758037],[58.84095621726802,75.85844831279042],[99.82785779692128,72.36925193383885],[47.26426910848174,88.47586499559782],[50.45815980285988,75.80985952982456],[60.45555629271532,42.50840943572217],[82.22666157785568,42.71987853716458],[88.9138964166533,69.80378889835472],[94.83450672430196,45.69430680250754],[67.31925746917527,66.58935317747915],[57.23870631569862,59.51428198012956],[80.36675600171273,90.96014789746954],[68.46852178591112,85.59430710452014],[42.0754545384731,78.84478600148043],[75.47770200533905,90.42453899753964],[78.63542434898018,96.64742716885644],[52.34800398794107,60.76950525602592],[94.09433112516793,77.15910509073893],[90.44855097096364,87.50879176484702],[55.48216114069585,35.57070347228866],[74.49269241843041,84.84513684930135],[89.84580670720979,45.35828361091658],[83.48916274498238,48.38028579728175],[42.2617008099817,87.10385094025457],[99.31500880510394,68.77540947206617],[55.34001756003703,64.9319380069486],[74.77589300092767,89.52981289513276]])\n",
    "y = np.array([0,0,0,1,1,0,1,1,1,1,0,0,1,1,0,1,1,0,1,1,0,1,0,0,1,1,1,0,0,0,1,1,0,1,0,0,0,1,0,0,1,0,1,0,0,0,1,1,1,1,1,1,1,0,0,0,1,0,1,1,1,0,0,0,0,0,1,0,1,1,0,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,0,1,1,0,1,1,0,1,1,1,1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6872aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def sigmoid(z):\n",
    "    \n",
    "    g_z = 1/(1+np.exp(-z))\n",
    "    \n",
    "    return g_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "920585b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost function\n",
    "def compute_cost(x, y, w, b):\n",
    "    \n",
    "    m, n = x.shape\n",
    "    cost = 0.0\n",
    "    \n",
    "    for i in range(m):\n",
    "        \n",
    "        z = np.dot(x[i],w) + b\n",
    "        f_x = sigmoid(z)\n",
    "        cost +=  -y[i]*np.log(f_x) - ((1-y[i])*np.log(1-f_x))  \n",
    "        \n",
    "    cost = cost/m\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b29233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent\n",
    "def compute_gradient(x, y, w, b, alpha):\n",
    "    \n",
    "    m,n = x.shape\n",
    "    dj_dw = np.zeros((n,))\n",
    "    dj_db = 0.0\n",
    "    \n",
    "    for i in range(0, m):\n",
    "        z = (np.dot(w, x[i]))+b\n",
    "        f_x = sigmoid(z)\n",
    "        error = f_x - y[i]\n",
    "        \n",
    "        for j in range(0, n):\n",
    "            dj_dw[j] = dj_dw[j] + error*x[i, j]\n",
    "        dj_db = dj_db + error\n",
    "        \n",
    "    w = w - alpha*(dj_dw/m)\n",
    "    b = b - alpha*(dj_db/m)\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9bf7de4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initializing parameters\n",
    "init_w = 0.01 * (np.random.rand(2) - 0.5)\n",
    "init_b = -8\n",
    "iterations = 10000\n",
    "alpha = 0.001\n",
    "\n",
    "# Initialining variables\n",
    "history_j =[]\n",
    "history_w = []\n",
    "history_b = []\n",
    "\n",
    "# Executing Gradient Descent\n",
    "w = init_w\n",
    "b = init_b\n",
    "for i in range(0, iterations+1):\n",
    "    cost = compute_cost(x, y, w, b)\n",
    "    parameters = compute_gradient(x, y, w, b, alpha)\n",
    "    history_j.append(cost)\n",
    "    history_w.append(parameters[0])\n",
    "    history_b.append(parameters[1])\n",
    "    w = parameters[0]\n",
    "    b = parameters[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d20e632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>J_wb</th>\n",
       "      <th>w</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.759109</td>\n",
       "      <td>[0.04652463184717567, 0.04354531927863724]</td>\n",
       "      <td>-7.999400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.977171</td>\n",
       "      <td>[0.07876639933762644, 0.07543070817947026]</td>\n",
       "      <td>-7.998964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.420343</td>\n",
       "      <td>[0.06887979878592668, 0.06522846644222512]</td>\n",
       "      <td>-7.999148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.305892</td>\n",
       "      <td>[0.06837721838638482, 0.06453846571834046]</td>\n",
       "      <td>-7.999177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.305582</td>\n",
       "      <td>[0.06857328319344021, 0.0645613419437977]</td>\n",
       "      <td>-7.999194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.301870</td>\n",
       "      <td>[0.07125308869086314, 0.06482840719812162]</td>\n",
       "      <td>-8.188564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.301869</td>\n",
       "      <td>[0.0712532342431487, 0.06482855486280444]</td>\n",
       "      <td>-8.188582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.301869</td>\n",
       "      <td>[0.07125337979498433, 0.06482870252702098]</td>\n",
       "      <td>-8.188601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.301868</td>\n",
       "      <td>[0.07125352534637003, 0.06482885019077124]</td>\n",
       "      <td>-8.188620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>0.301868</td>\n",
       "      <td>[0.07125367089730578, 0.06482899785405521]</td>\n",
       "      <td>-8.188638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10001 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           J_wb                                           w         b\n",
       "0      4.759109  [0.04652463184717567, 0.04354531927863724] -7.999400\n",
       "1      0.977171  [0.07876639933762644, 0.07543070817947026] -7.998964\n",
       "2      0.420343  [0.06887979878592668, 0.06522846644222512] -7.999148\n",
       "3      0.305892  [0.06837721838638482, 0.06453846571834046] -7.999177\n",
       "4      0.305582   [0.06857328319344021, 0.0645613419437977] -7.999194\n",
       "...         ...                                         ...       ...\n",
       "9996   0.301870  [0.07125308869086314, 0.06482840719812162] -8.188564\n",
       "9997   0.301869   [0.0712532342431487, 0.06482855486280444] -8.188582\n",
       "9998   0.301869  [0.07125337979498433, 0.06482870252702098] -8.188601\n",
       "9999   0.301868  [0.07125352534637003, 0.06482885019077124] -8.188620\n",
       "10000  0.301868  [0.07125367089730578, 0.06482899785405521] -8.188638\n",
       "\n",
       "[10001 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe with values of cost and model parameters after each iteration\n",
    "pd.DataFrame({'J_wb':history_j, 'w':history_w, 'b':history_b})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d9c823a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y for given value of x is 0\n"
     ]
    }
   ],
   "source": [
    "# Model prediction\n",
    "\n",
    "# New value of x for prediction\n",
    "new_x = [39.0,76.0]\n",
    "\n",
    "# Prediction result\n",
    "z = np.dot(history_w[-1], new_x)+history_b[-1]\n",
    "f_x = sigmoid(z)\n",
    "\n",
    "# Class value\n",
    "p =None\n",
    "\n",
    "if f_x > 0.5:\n",
    "    p = 1\n",
    "else:\n",
    "    p = 0\n",
    "\n",
    "# Output\n",
    "print(\"y for given value of x is\", p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
