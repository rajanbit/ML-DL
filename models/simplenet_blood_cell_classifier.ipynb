{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UHjMH3oyYXZg"
   },
   "outputs": [],
   "source": [
    "# Importing modules\n",
    "import os\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zzHNvl1PYng2"
   },
   "outputs": [],
   "source": [
    "# Path to train, val and test folder\n",
    "train_dir = './train/'\n",
    "val_dir = './val/'\n",
    "test_dir = './test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DqdpuprPw_E3"
   },
   "outputs": [],
   "source": [
    "# Transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "# Train dataset\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform)\n",
    "\n",
    "# Validation dataset\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform)\n",
    "\n",
    "# Test datasets\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform)\n",
    "\n",
    "# Train dataloader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128)\n",
    "\n",
    "# Val dataloader\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=128)\n",
    "\n",
    "# Test dataloader\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5zR1UF6OllF5"
   },
   "outputs": [],
   "source": [
    "# SimpleNet Model\n",
    "class SimpleNet(nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    super(SimpleNet, self).__init__()\n",
    "    self.fc1 = nn.Linear(12288, 84)\n",
    "    self.fc2 = nn.Linear(84, 50)\n",
    "    self.fc3 = nn.Linear(50, len(os.listdir(train_dir)))\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = torch.relu(self.fc1(x))\n",
    "    x = torch.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZuiLTrFIoSFH"
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "model = SimpleNet()\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "FskzZ9ua0J0X"
   },
   "outputs": [],
   "source": [
    "# Loading model to device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qLvaVP-W0YhP",
    "outputId": "e8a8bde2-8e4b-4e0d-f1e9-c708e3f5dee6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Validation Loss: 3.953335616964614\n",
      "Epoch 2 | Validation Loss: 1.286982897669077\n",
      "Epoch 3 | Validation Loss: 0.7420513987541199\n",
      "Epoch 4 | Validation Loss: 0.5281069993972778\n",
      "Epoch 5 | Validation Loss: 0.5656817883253098\n",
      "Epoch 6 | Validation Loss: 0.4726168870925903\n",
      "Epoch 7 | Validation Loss: 0.45422913134098053\n",
      "Epoch 8 | Validation Loss: 0.42337810099124906\n",
      "Epoch 9 | Validation Loss: 0.3951799660921097\n",
      "Epoch 10 | Validation Loss: 0.3979069232940674\n",
      "Epoch 11 | Validation Loss: 0.34705943763256075\n",
      "Epoch 12 | Validation Loss: 0.33448357582092286\n",
      "Epoch 13 | Validation Loss: 0.3315883904695511\n",
      "Epoch 14 | Validation Loss: 0.3041655898094177\n",
      "Epoch 15 | Validation Loss: 0.3001324951648712\n",
      "Epoch 16 | Validation Loss: 0.29386927783489225\n",
      "Epoch 17 | Validation Loss: 0.286748132109642\n",
      "Epoch 18 | Validation Loss: 0.28279435336589814\n",
      "Epoch 19 | Validation Loss: 0.27896781265735626\n",
      "Epoch 20 | Validation Loss: 0.2756479024887085\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(20):\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = batch\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            inputs, targets = batch\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    average_val_loss = val_loss / len(val_dataloader)\n",
    "    print(f\"Epoch {epoch+1} | Validation Loss: {average_val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "rFff_84R7139"
   },
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_test = []\n",
    "\n",
    "# Testing loop\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        inputs, targets = batch\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        pred = torch.argmax(outputs, dim=1)\n",
    "        y_pred.extend(pred.cpu().numpy())\n",
    "        y_test.extend(targets.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "dyTi-XmaoSKV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    basophil       0.93      0.77      0.84       100\n",
      "  lymphocyte       0.80      0.94      0.87       100\n",
      "\n",
      "    accuracy                           0.85       200\n",
      "   macro avg       0.87      0.85      0.85       200\n",
      "weighted avg       0.87      0.85      0.85       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metric\n",
    "report = classification_report(y_test, y_pred, target_names=test_dataset.classes)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
