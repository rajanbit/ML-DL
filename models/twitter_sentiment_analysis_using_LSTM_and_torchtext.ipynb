{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fd4ffb9-8dfd-4e2a-b87a-fc19c9ca7fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing modules\n",
    "import pandas as pd\n",
    "from torchtext import data\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3b0d6a5-ed8e-47f0-bf0f-097d27cd2b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2014432769</td>\n",
       "      <td>Wed Jun 03 01:30:41 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>zxhoon</td>\n",
       "      <td>@chickpea981 happy bday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2178933826</td>\n",
       "      <td>Mon Jun 15 08:24:46 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>kerimcinerney</td>\n",
       "      <td>@PamelaGlasner pleasure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1979723018</td>\n",
       "      <td>Sun May 31 04:14:43 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jessicaspence</td>\n",
       "      <td>Watching perfum, eating cake, lots of cuddles....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2069191661</td>\n",
       "      <td>Sun Jun 07 15:25:44 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>nydia_nicole</td>\n",
       "      <td>And she say u have to press the break then pus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1770778240</td>\n",
       "      <td>Mon May 11 22:13:18 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>FireflyShop</td>\n",
       "      <td>vdoBug kids DVD navigator giveaway #2 winners ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0           1                             2         3              4  \\\n",
       "0  1  2014432769  Wed Jun 03 01:30:41 PDT 2009  NO_QUERY         zxhoon   \n",
       "1  1  2178933826  Mon Jun 15 08:24:46 PDT 2009  NO_QUERY  kerimcinerney   \n",
       "2  1  1979723018  Sun May 31 04:14:43 PDT 2009  NO_QUERY  jessicaspence   \n",
       "3  0  2069191661  Sun Jun 07 15:25:44 PDT 2009  NO_QUERY   nydia_nicole   \n",
       "4  1  1770778240  Mon May 11 22:13:18 PDT 2009  NO_QUERY    FireflyShop   \n",
       "\n",
       "                                                   5  \n",
       "0                           @chickpea981 happy bday   \n",
       "1                           @PamelaGlasner pleasure   \n",
       "2  Watching perfum, eating cake, lots of cuddles....  \n",
       "3  And she say u have to press the break then pus...  \n",
       "4  vdoBug kids DVD navigator giveaway #2 winners ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data | tweets dataframe\n",
    "tdf = pd.read_csv(\"twitter_50K_training_data.csv\", header=None, encoding=\"cp1252\")\n",
    "\n",
    "# Dataframe manipulation\n",
    "tdf[0] = tdf[0].astype(\"category\").cat.codes\n",
    "\n",
    "# Saving Tweets dataframe\n",
    "tdf.to_csv(\"training-processed.csv\", header=None, index=None)\n",
    "\n",
    "# Dataframe summary\n",
    "tdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49d3f051-a79f-4fdf-871e-c9efe4815322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining datatypes fields\n",
    "LABEL = data.LabelField()\n",
    "TWEET = data.Field(lower=True)\n",
    "\n",
    "# Creating dataset\n",
    "fields = [('label',LABEL), ('id',None),('date',None),('query',None),('name',None),('tweet', TWEET)]\n",
    "tData = data.TabularDataset(\"training-processed.csv\", format=\"CSV\",fields=fields, skip_header=False)\n",
    "\n",
    "# Splitting dataset into train, val and test\n",
    "train, val, test = tData.split(split_ratio=[0.7, 0.2, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12f249dc-422f-404e-98bd-d2ee271242fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building vocabulary\n",
    "TWEET.build_vocab(train, max_size=20000)\n",
    "LABEL.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eded41c8-d5c9-49e3-aee2-90015b02bc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining device\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f09f0b50-33ec-497b-a805-f0baaa162793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "train_dataloader, val_dataloader, test_dataloader = data.BucketIterator.splits((train, val, test),\n",
    "                                                                               batch_size=64, \n",
    "                                                                               device=device, \n",
    "                                                                               sort_key=lambda x: len(x.tweet), \n",
    "                                                                               sort_within_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdbc6656-d8d0-413b-ad60-c6d354fb77c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM model\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding_dim, vocab_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.encoder = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size, num_layers=1)\n",
    "        self.predictor = nn.Linear(hidden_size, 2)\n",
    "    def forward(self, x):\n",
    "        output, (hidden, _) = self.encoder(self.embedding(x))\n",
    "        pred = self.predictor(hidden.squeeze(0))\n",
    "        return pred\n",
    "\n",
    "# Model\n",
    "model = LSTM(100, 300, 20002)\n",
    "\n",
    "# Loading model to device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87d08176-f4f7-4d99-b6d8-b08d23d5ed84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (embedding): Embedding(20002, 300)\n",
       "  (encoder): LSTM(300, 100)\n",
       "  (predictor): Linear(in_features=100, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model architecture\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df111b1f-b73a-405f-9216-1f1639700aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "744148ba-555b-415f-9a60-8d54f4ce51c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Validation Loss: 7.573331027468549\n",
      "Epoch 2 | Validation Loss: 7.9871179280401785\n",
      "Epoch 3 | Validation Loss: 8.496222077291224\n",
      "Epoch 4 | Validation Loss: 9.717823199833497\n",
      "Epoch 5 | Validation Loss: 10.349119643244562\n",
      "Epoch 6 | Validation Loss: 11.471383602558811\n",
      "Epoch 7 | Validation Loss: 11.39102231362198\n",
      "Epoch 8 | Validation Loss: 11.706954636905767\n",
      "Epoch 9 | Validation Loss: 12.906469008590602\n",
      "Epoch 10 | Validation Loss: 13.366947120503534\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(10):\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for batch_idx, batch in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch.tweet)\n",
    "        loss = criterion(outputs, batch.label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(val_dataloader):\n",
    "            outputs = model(batch.tweet)\n",
    "            loss = criterion(outputs, batch.label)\n",
    "            val_loss += loss.data.item() * batch.tweet.size(0)\n",
    "\n",
    "    average_val_loss = val_loss / len(val_dataloader)\n",
    "    print(f\"Epoch {epoch+1} | Validation Loss: {average_val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "055d76e9-34ef-4f7b-9702-f4df9beb479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_test = []\n",
    "\n",
    "# Testing loop\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(test_dataloader):\n",
    "        outputs = model(batch.tweet)\n",
    "        pred = torch.argmax(outputs, dim=1)\n",
    "        y_pred.extend(pred.cpu().numpy())\n",
    "        y_test.extend(batch.label.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2414c40-22f9-4f2c-b1dc-fe9760d26d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.74      0.73      5051\n",
      "           0       0.73      0.72      0.72      4949\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.73      0.73      0.73     10000\n",
      "weighted avg       0.73      0.73      0.73     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metric\n",
    "report = classification_report(y_test, y_pred, target_names=LABEL.vocab.freqs.keys())\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
